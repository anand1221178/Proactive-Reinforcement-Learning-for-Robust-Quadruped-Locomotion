# RLâ€‘Portfolio: Reconfigurable Reinforcementâ€‘Learning Research Framework

[![license](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
[![python](https://img.shields.io/badge/Python-3.11%2b-informational)](https://www.python.org/)
[![hydra](https://img.shields.io/badge/Config-Hydra%201.3â€‘blueviolet)](https://github.com/facebookresearch/hydra)
[![wandb](https://img.shields.io/badge/Tracking-W%26B-f79520)](https://wandb.ai/)

> **ReleaseÂ status**: ğŸš§  Alpha &ndash; initial scaffolding for AnandÂ Patelâ€™s MSc/PhD reinforcementâ€‘learning project.

---

## âœ¨Â Project Overview
This repository hosts a **researchâ€‘grade pipeline** for training, evaluating, and analysing reinforcementâ€‘learning (RL) agents in simulated tasks.  
The key design goal is **rapid iteration on your workstation** followed by **seamless scaleâ€‘out on an HPC cluster** (GPU Slurm farm).  
Features include:

| Feature | Why it matters |
|---------|----------------|
| **Hydraâ€‘powered hierarchical configs** | Oneâ€‘line overrides, composable â€œpyramidâ€ ablations, automatic config logging. |
| **Stableâ€‘Baselines3 / JAX backâ€‘end** | Start fast with PyTorch, switch to JAX for largeâ€‘scale vectorised training. |
| **WeightsÂ &Â Biases integration** | Live dashboards + offline sync; keeps every run reproducible (git SHA, GPU type, hyperâ€‘params). |
| **CondaÂ +Â Docker/Singularity** | Identical environments locally and on cluster; GPU drivers handled via NVIDIA images. |
| **Slurm templates** | Zeroâ€‘boilerplate submission: `sbatch scripts/submit_job.slurm algo=ppo total_timesteps=1e8`. |
| **CI & linting** | GitHubÂ Actions, `preâ€‘commit`, `pytest` smoke tests guard code quality. |

---

## ğŸ—ºï¸Â Directory Structure

```
rlâ€‘project/
â”œâ”€â”€ config/                  # Hydra config tree (YAML)
â”‚   â”œâ”€â”€ algo/                # PPO, SAC, etc. inherit from base_algo.yaml
â”‚   â”œâ”€â”€ env/                 # Sim versions, domainâ€‘randomisation toggles
â”‚   â”œâ”€â”€ hydra/               # Jobâ€‘logging, sweep configs
â”‚   â”œâ”€â”€ overrides/           # Figureâ€‘ready presets
â”‚   â””â”€â”€ experiment.yaml      # Root config composing the pieces
â”œâ”€â”€ src/                     # Importable Python package `rl_project`
â”‚   â”œâ”€â”€ agents/              # Custom policy nets, loss functions
â”‚   â”œâ”€â”€ envs/                # Gymnasiumâ€‘compatible simulators / wrappers
â”‚   â”œâ”€â”€ training/            # train.py, evaluate.py, rollout.py
â”‚   â”œâ”€â”€ utils/               # misc helpers: seeding, logging, ablations
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ scripts/                 # Pure Bash helpers & Slurm templates
â”‚   â”œâ”€â”€ local_setup.sh
â”‚   â”œâ”€â”€ cluster_setup.sh
â”‚   â”œâ”€â”€ submit_job.slurm
â”‚   â””â”€â”€ sweep.yaml
â”œâ”€â”€ environment.yml          # Conda spec (GPU + CPU fallback)
â”œâ”€â”€ Dockerfile               # Builds nvidiaâ€‘cuda runtime image
â”œâ”€â”€ tests/                   # PyTest smoke & unit tests
â”œâ”€â”€ .preâ€‘commitâ€‘config.yaml  # Black, isort, flake8, nbstripout
â”œâ”€â”€ .github/workflows/ci.yml # Continuousâ€‘integration pipeline
â”œâ”€â”€ README.md                # â† you are here
â””â”€â”€ LICENSE
```

---

## ğŸ—ï¸Â Tech Stack & Rationale

| Layer | Tooling | Rationale |
|-------|---------|-----------|
| **Language** | PythonÂ 3.11 | Wide ecosystem, async improvements, structural patternâ€‘matching. |
| **RL Library** | Stableâ€‘Baselines3 (PyTorchÂ 2.3) â€¢ optional CleanRLâ€‘JAX | SB3 is battleâ€‘tested & fast to prototype; JAX unlocks TPU/GPU vectorisation later. |
| **Configs** | HydraÂ 1.3 + OmegaConf | Nested YAML with inheritance, jobâ€‘id interpolation, dynamic defaults. |
| **Experiment tracking** | WeightsÂ &Â Biases | Autoâ€‘logs git, hardware, gradients; clusterâ€‘safe offline mode. |
| **Package/env** | Conda (mamba) | GPU builds via `pytorch` channel; clusters already ship Conda modules. |
| **Container** | Docker â†’ Singularity(.sif) | Immutable environment; Slurm can run `--container-image`. |
| **Scheduler** | Slurm | Standard at CHPC & most university clusters. |
| **CI/CD** | GitHubÂ Actions | Free linux runners for lint + CPU unit tests. |
| **Code Style** | `black`, `isort`, `flake8`, type hints (`mypy`) | Enforced via preâ€‘commit on every commit / PR. |

---

## ğŸš€Â Getting Started

### 1. Clone & bootstrap (local workstation)

```bash
git clone https://github.com/anand1221178/Proactive-Reinforcement-Learning-for-Robust-Quadruped-Locomotion.git
cd rlâ€‘project
bash scripts/local_setup.sh      # installs Conda env + preâ€‘commit hooks
conda activate rlproj
python -m rl_project.training.train dry_run=true
```

`dry_run=true` executes a 32â€‘step rollout to verify the plumbing.

### 2. Cluster setup (Slurm GPU node)

```bash
module load miniconda/23.1 cuda/11.8 git
bash scripts/cluster_setup.sh     # creates identical Conda env on $HOME/.conda
sbatch scripts/submit_job.slurm algo=ppo total_timesteps=1e7
```

### 3. Container workflow (optional but recommended)

```bash
docker build -t rlproj:latest .
# On cluster login node
singularity build rlproj.sif docker-daemon://rlproj:latest
sbatch --container-image=rlproj.sif scripts/submit_job.slurm algo=sac
```

Offline W&B logs accumulate under `$WANDB_DIR` and can be synced later:

```bash
wandb sync /scratch/$USER/wandb/offlineâ€‘runs
```

---

## âš™ï¸Â ConfigurationÂ 101

Hydra composes configs from `config/` according to the **defaults list** at the top of `experiment.yaml`.

```yaml
# config/experiment.yaml
defaults:
  - algo: ppo
  - env: sim_v1
  - hydra: base
  - _self_

total_timesteps: 2_000_000
seed: 123
```

Override anything from the CLI:

```bash
python -m rl_project.training.train algo=ppo clip_range=0.1 env=sim_v2 seed=42
```

Create *pyramids* for ablations by layering multiple algos or env options:

```bash
python -m rl_project.training.train   +algo=ppo   +algo.lstm=true   +env=sim_v2   +env.domain_rand=true
```

Hydra writes the **full, resolved config** and CLI exactly as run into
```
outputs/
â””â”€â”€ 2025â€‘06â€‘20/16â€‘58â€‘42/   # timestamp
    â”œâ”€â”€ .hydra/config.yaml
    â””â”€â”€ train.log
```

---

## ğŸ“ŠÂ Experiment Tracking

* **wandb run**: metrics, gradients, videos, git SHA, CUDA driver, peak GPU mem.
* **Group key**: `env-name_algo-seed`, e.g. `sim_v2_ppo-42`.
* **Sweep**: define grid/random in `scripts/sweep.yaml`, run `wandb sweep && wandb agent`.

> **Privacy**: offline mode is autoâ€‘enabled when `$WANDB_MODE=offline`  
> Synchronise later with `wandb sync`.

---

## ğŸ§ªÂ Ablation & Sweep Workflow

| Step | Command |
|------|---------|
| 1. Define base config | `config/algo/ppo.yaml`, `config/env/sim_v2.yaml` |
| 2. Add variant YAMLs | e.g. `config/algo/ppo_small_lr.yaml` |
| 3. Launch sweep | `wandb sweep scripts/sweep.yaml` |
| 4. Agent script | Hydra injects params â†’ SB3 trainer |


---

## ğŸ–¥ï¸Â Running Evaluations

```bash
python -m rl_project.training.evaluate   checkpoint=outputs/2025â€‘06â€‘20/16â€‘58â€‘42/model.zip   n_episodes=100   render=false
```

Results (return, length, custom metrics) are dumped to `.csv` and logged to W&B *table*.

---

## ğŸ› ï¸Â Developer Guide

* **Preâ€‘commit**: autoâ€‘format on commit. Run manually via `preâ€‘commit run --all-files`.
* **Unit tests**: `pytest -q tests/`. Smoke tests run on CPU under CI.
* **Docstrings** follow the *Google* style. Public functions: full docs; private: brief oneâ€‘liner.
* **Type hints**: mandatory for new functions (`from __future__ import annotations`).
* **Branch naming**: `feat/<topic>`, `fix/<bug>`, `exp/<sweepâ€‘name>`.

---

## ğŸ¤Â Contributing

1. Fork â†’ `git checkout -b feat/my-awesome-feature`
2. Commit (+ tests!) â†’ open Pull Request.
3. Ensure CI passes (lint & tests).
4. PR will trigger GPU smoke run on cluster (selfâ€‘hosted runner).

---

## ğŸ“„Â License

This work is released under the **MIT License** â€“ see [LICENSE](LICENSE).

---

## ğŸ“šÂ References

* Schulman, J. *etÂ al.* â€œProximal Policy Optimization Algorithms.â€ 2017.
* Raffin, A. *etÂ al.* â€œStable Baselines3.â€ *Journal of Machine Learning Open Source Software*,Â 2021.

---

## ğŸ“«Â Contact

Questions, issues, ideas for wild ablations?  
**AnandÂ Patel** â€“ <anand.patel@students.wits.ac.za>  

---

Happy training & may your gradients be ever in your favour ğŸ™Œ