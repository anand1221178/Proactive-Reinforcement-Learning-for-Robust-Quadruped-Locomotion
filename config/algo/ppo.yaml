_target_: stable_baselines3.PPO
policy: "MlpPolicy"
learning_rate: 3.0e-4
n_steps: 2048
batch_size: 64
gamma: 0.99
gae_lambda: 0.95
clip_range: 0.2
ent_coef: 0.0

# OVERRIDE EXAMPLE
# python -m rl_project.training.train algo=ppo clip_range=0.1 env=sim_v2 seed=42